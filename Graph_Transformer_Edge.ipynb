{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "050568ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/doductai/Desktop/AI and ML/DGL projects/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import dgl.sparse as dglsp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from dgl.data import AsGraphPredDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from ogb.graphproppred import collate_dgl, DglGraphPropPredDataset, Evaluator\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2968d34",
   "metadata": {},
   "source": [
    "## 1. Sparse attention\n",
    "<img src=\"graph_edge.png\" width=\"500\" height=\"300\">\n",
    "\n",
    "### (a) Traditional Attention: $Q, K, V$\n",
    "1. Attention coefficients:\n",
    "<center>\n",
    "$\\text{attn_coeffs(Q,K)}=\\text{softmax}\\left(\\dfrac{QK^T}{\\sqrt{d_k}}\\right)$ with $d_k =$ dimensionality of $Q$ and $K$\n",
    "<center>\n",
    "2. Combine attention coefficients and values to give output\n",
    "<center>\n",
    "$\\text{attention}(Q,K,V)=\\text{attn_coeffs(Q,K)}V$\n",
    "<center>\n",
    "\n",
    "### (b) Sparse Attention: \n",
    "Input: $Q=[N,d], K=[N,d], V=[N,d], A=[N,N], E=[N,N,d]$\n",
    "1. Attention coefficients\n",
    "<center>\n",
    "$\\text{attn_coeffs(Q,K,A,E)}=\\text{softmax}\\left((\\dfrac{QK^T}{\\sqrt{d}}*A)*E\\right)$ \n",
    "<center>\n",
    "2. Aggregate over edge features to get coefficients as scalars:\n",
    "<center>\n",
    "$\\text{attn_coeffs(Q,K,A,E)}=\\text{attn_coeffs(Q,K,A,E)}.sum(dim=-1) = [N,N]$\n",
    "<center>\n",
    "3. Combine attention coefficients and values to give output\n",
    "<center>\n",
    "$\\text{attention}(Q,K,A,E,V)=\\text{attn_coeffs(Q,K,A,E)}V$\n",
    "<center>\n",
    "    \n",
    "### (c) Attention module structure\n",
    "(1) A = adjacency matrix= [N,N], \\\n",
    "        (2) h_x = hidden representation of node features $ = [N,\\text{hidden_dim}]$,\\\n",
    "        (3) h_e = hidden representation of edge features $ = [N,N,\\text{hidden_dim}]$\n",
    "    \n",
    "1. Project the input into Q, K, V, E: \n",
    "    $$Q, K, V = [N,\\text{hidden_dim}], \\ E=[N,N,\\text{hidden_dim}]$$\n",
    "2. Reshape Q,K,V,E according to num_heads $n_h$: \n",
    "    $$\\text{hidden_dim}=d_hn_h \\rightarrow Q,K,V=[N,d_h,n_h], E=[N,N,d_h,n_h]$$\n",
    "3. Compute attention coefficients: * means pointwise multiplication\n",
    "$$\\text{attn_coeffs(Q,K,A,E)}=\\text{softmax}\\left((\\dfrac{QK^T}{\\sqrt{d_k}}*A)*E\\right)=[N,N,d_h,n_h]$$\n",
    "4. Aggregate along edge dimension to get the coefficients as scalars\n",
    "    $$\\text{attn_coeffs(Q,K,A,E)}=\\text{attn_coeffs(Q,K,E)}.sum(dim=-2)=[N,N,nh]$$\n",
    "5. Combine with value $V$:\n",
    "$$\\text{ouput(Q,K,E,A,V)}=\\text{attn_coeffs}(Q,K,A,E)V=[N,d_h,n_h]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5d49028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class SparseMultiHeadAttention(nn.Module):\n",
    "    def __init__(self,hidden_dim=64,num_heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_heads=num_heads\n",
    "        self.hidden_dim=hidden_dim\n",
    "        \n",
    "        self.linear_q=nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.linear_k=nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.linear_v=nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.linear_e=nn.Linear(hidden_dim,hidden_dim)\n",
    "        \n",
    "        # projection of output O_h, O_e\n",
    "        self.proj_h=nn.Linear(hidden_dim,hidden_dim)\n",
    "        self.proj_e=nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self,A,h_x,h_e):\n",
    "        \n",
    "        # A   = adjacency matrix = [N,N] \n",
    "        # h_x = hidden representation of node features = [N,hidden_dim]\n",
    "        # h_e = hidden representation of edge features = [N,N,hidden_dim]\n",
    "        \n",
    "        # Extract N, nh, dh\n",
    "        N=len(h_x)                # number of nodes\n",
    "        nh=self.num_heads\n",
    "        dh=self.hidden_dim//nh\n",
    "        \n",
    "        # compute q,k,v,e and reshape into heads\n",
    "        q=self.linear_q(h_x).reshape(N,dh,nh)\n",
    "        k=self.linear_k(h_x).reshape(N,dh,nh)\n",
    "        v=self.linear_v(h_x).reshape(N,dh,nh)\n",
    "        \n",
    "        e=self.linear_e(h_e).reshape(N,N,dh,nh)\n",
    "\n",
    "        # implicit attention coefficients = (qk^T/sqrt(dh)*A)*e\n",
    "        \n",
    "        attn_coeff_implicit=dglsp.bsddmm(A,q,k.transpose(1,0))/np.sqrt(dh) # [N,N,nh]\n",
    "        \n",
    "        attn_coeff_implicit=dgl.sparse.SparseMatrix.to_dense(attn_coeff_implicit) # [N,N,nh]\n",
    "        \n",
    "        # multiply attn_coeff_implicit into e: multiply elementwise \n",
    "        attn_coeffs=attn_coeff_implicit.reshape(N,N,1,nh)*e # [N,N,dh,nh]*[N,N,1,nh]=[N,N,dh,nh]        \n",
    "        \n",
    "        # keep a copy of e for FFN_e\n",
    "        e_out=attn_coeffs.view(N,N,-1)                      # [N,N,hidden_dim]\n",
    "        \n",
    "        # take sum along dimension d_h\n",
    "        attn_coeffs=torch.exp(torch.sum(attn_coeffs,dim=-2).clamp(-5,5)) # [N,N,nh]\n",
    "        \n",
    "        \n",
    "        # apply softmax\n",
    "        attn_coeffs=attn_coeffs.softmax(dim=-2)                     # [N,N,nh]\n",
    "        \n",
    "        \n",
    "        # combine with v to give output for FFN_v\n",
    "        #              attn_coeffs=[N,N,nh], v=[N,dh,nh] \n",
    "        h_out=torch.matmul(attn_coeffs.transpose(-1,-2).transpose(-2,-3),\n",
    "                           v.transpose(-1,-2).transpose(-2,-3))     # [nh,N,dh]\n",
    "        h_out=(h_out.transpose(-2,-3).transpose(-2,-1)).reshape(N,-1) # [N,hidden_dim]\n",
    "\n",
    "\n",
    "        # projection of output O_h, O_e\n",
    "        h_out=self.proj_h(h_out)\n",
    "        e_out=self.proj_e(e_out)\n",
    "        \n",
    "        return h_out,e_out \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7afe635b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 64]) torch.Size([19, 19, 64])\n"
     ]
    }
   ],
   "source": [
    "# sannity check\n",
    "hidden_dim=64\n",
    "num_heads=4\n",
    "N,nh,dh=19,4,8\n",
    "\n",
    "# create a sparse adjacency matrix\n",
    "src=torch.randint(high=19,size=(40,))\n",
    "dst=torch.randint(high=19,size=(40,))\n",
    "A=dglsp.spmatrix(torch.stack([src,dst]),shape=(N,N))\n",
    "\n",
    "# node and edge features\n",
    "h_x=torch.rand((N,hidden_dim))\n",
    "h_e=torch.rand((N,N,hidden_dim))\n",
    "\n",
    "# model\n",
    "SparseMHA=SparseMultiHeadAttention(hidden_dim,num_heads)\n",
    "h_out, e_out=SparseMHA(A,h_x,h_e)\n",
    "print(h_out.shape, e_out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd99474",
   "metadata": {},
   "source": [
    "## 2. Graph Transformer Layer\n",
    "<img src=\"graph_edge.png\" width=\"400\" height='400'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e237c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTLayer(nn.Module):\n",
    "    def __init__(self,hidden_dim=64,num_heads=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.num_heads=num_heads\n",
    "        \n",
    "        # attention module\n",
    "        self.attention=SparseMultiHeadAttention(hidden_dim,num_heads)\n",
    "        \n",
    "        \n",
    "        # batch normalization\n",
    "        self.bnh_1=nn.BatchNorm1d(hidden_dim)\n",
    "        self.bnh_2=nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        self.bne_1=nn.BatchNorm1d(hidden_dim)\n",
    "        self.bne_2=nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        # ffn_h and ffn_e\n",
    "        self.ffn_h=nn.Sequential(\n",
    "            nn.Linear(hidden_dim,hidden_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim*2,hidden_dim)\n",
    "        )\n",
    "        self.ffn_e=nn.Sequential(\n",
    "            nn.Linear(hidden_dim,hidden_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim*2,hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self,A,h_x,h_e):\n",
    "        \n",
    "        N=h_e.shape[0]\n",
    "        \n",
    "        # retain for 1st residual connection\n",
    "        h1,e1=h_x,h_e \n",
    "        \n",
    "        # attention module\n",
    "        h,e=self.attention(A,h_x,h_e)\n",
    "        \n",
    "        \n",
    "        # First add and norm\n",
    "        h=self.bnh_1(h+h1)\n",
    "        \n",
    "        e=self.bne_1((e+e1).reshape(-1,self.hidden_dim))\n",
    "        e=e.reshape(N,N,hidden_dim)\n",
    "        \n",
    "        # retain for 2nd residual connection\n",
    "        h2,e2=h,e\n",
    "        \n",
    "        # ffn layers\n",
    "        h=self.ffn_h(h)\n",
    "        e=self.ffn_e(e)\n",
    "        \n",
    "        # Second add and norm\n",
    "        h=self.bnh_2(h+h2)\n",
    "        \n",
    "        e=self.bne_2((e+e2).reshape(-1,self.hidden_dim))\n",
    "        e=e.reshape(N,N,hidden_dim)\n",
    "        \n",
    "        return h,e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b1e5c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([19, 64]), torch.Size([19, 19, 64]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "layer=GTLayer(hidden_dim=64,num_heads=4)\n",
    "h,e=layer(A,h_x,h_e)\n",
    "h.shape, e.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579d5f3",
   "metadata": {},
   "source": [
    "## 3. Graph Transformer Model \n",
    "We will implemement: Inputs -> GTLayers -> SumPooling -> Classifier \n",
    "        \n",
    "1. SumPooling: extra pooler stacked on top of GT layers to aggregate node features of the same graph.\n",
    "2. Classifier = linear(d,d/2)+relu+linear(d/2,d/4)+relu+linear(d/4,out_size).\n",
    "\n",
    "Inputs: (1) Graph g, (2) Node features X, (3) pos_enc (Laplacian encoding): shape [N,2]\n",
    "\n",
    "First, we pass original data (dim d) into hidden_dim (that will be passed to the model):\n",
    "1. Project the nodes into hidden_dim: h=nn.Linear(d,hidden_dim)(x)\n",
    "2. Add position encoding to all nodes: h=h+pos_enc(h)\n",
    "\n",
    "Now iterate the output through layers:\n",
    "1. Compute adjaceny matrix A by g.edges(): indices=torch.stack(g.edges()), A=dglsp.spmatrix(indices,shape=(N,N))\n",
    "2. Pass h through the layers: h=self.layer(A,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94666628",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTModel(nn.Module):\n",
    "    def __init__(self,out_size=1,hidden_dim=64,num_heads=4,pos_enc_dim=10,\n",
    "                 num_layers=4,edge_dim=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # atom encoder to project x into hidden representation h\n",
    "        self.atom_encoder=AtomEncoder(hidden_dim)\n",
    "        \n",
    "        # map laplacian position encoding pos_enc into hidden_dim\n",
    "        self.pos_linear=torch.nn.Linear(pos_enc_dim,hidden_dim)\n",
    "        \n",
    "        # map edge_dim into hidden_dim\n",
    "        self.linear_e=torch.nn.Linear(edge_dim,hidden_dim)\n",
    "        \n",
    "        # stack of graph transformer layers\n",
    "        self.layers=nn.ModuleList(\n",
    "            [GTLayer(hidden_dim,num_heads) for _ in range(num_layers)]\n",
    "        )\n",
    "        \n",
    "        # pooling layer\n",
    "        self.pooler=dglnn.SumPooling()\n",
    "        \n",
    "        # classifier layer\n",
    "        self.classifier=nn.Sequential(nn.Linear(hidden_dim,hidden_dim//2),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(hidden_dim//2,hidden_dim//4),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Linear(hidden_dim//4,out_size))\n",
    "        \n",
    "        \n",
    "    def forward(self,g,x,pos_enc):      # g = nx graph\n",
    "        \n",
    "        indices=torch.stack(g.edges())\n",
    "        N=g.num_nodes()\n",
    "        A=dglsp.spmatrix(indices,shape=(N,N))\n",
    "        \n",
    "        h=self.atom_encoder(x)+self.pos_linear(pos_enc)\n",
    "        \n",
    "        # create matrix e=[N,N,hidden_dim] with e[i,j] = feature of edge e_ij\n",
    "        e=self.linear_e(g.edata['feat'].float())              # [Ne,hidden_dim]\n",
    "        e=dglsp.spmatrix(indices,e,shape=(N,N))               # sparse matrix [N,N,hidden_dim]\n",
    "        e=e.to_dense()                                        # [N,N,hidden_dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            h,e=layer(A,h,e)\n",
    "        \n",
    "        # pooler aggregates node features of nodes in g\n",
    "        h=self.pooler(g,h)\n",
    "        \n",
    "        \n",
    "        # classify based on the aggregated node features\n",
    "        h=self.classifier(h)\n",
    "        \n",
    "        return h\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d6318",
   "metadata": {},
   "source": [
    "## 4. Data and Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e3b19c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Load dataset as graph prediction data\n",
    "dataset = AsGraphPredDataset(\n",
    "    DglGraphPropPredDataset(\"ogbg-molhiv\", \"./data/OGB\")\n",
    ")\n",
    "\n",
    "# downsample the dataset for faster training time\n",
    "train_size, val_size, test_size = len(dataset.train_idx), len(dataset.val_idx), len(dataset.test_idx)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_idx = dataset.train_idx[torch.LongTensor(random.sample(range(train_size), 2000))]\n",
    "val_idx = dataset.val_idx[torch.LongTensor(random.sample(range(val_size), 1000))]\n",
    "test_idx = dataset.test_idx[torch.LongTensor(random.sample(range(test_size), 1000))]\n",
    "\n",
    "\n",
    "# split data into train/validation/test\n",
    "batch_size=32\n",
    "train_loader=GraphDataLoader(dataset[train_idx],\n",
    "                             batch_size=batch_size,shuffle=True,collate_fn=collate_dgl)\n",
    "val_loader=GraphDataLoader(dataset[val_idx],\n",
    "                             batch_size=batch_size,shuffle=False,collate_fn=collate_dgl)\n",
    "test_loader=GraphDataLoader(dataset[test_idx],\n",
    "                             batch_size=batch_size,shuffle=False,collate_fn=collate_dgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ababbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Laplacian PE: 100%|██████████| 4000/4000 [00:07<00:00, 559.58it/s]\n"
     ]
    }
   ],
   "source": [
    "# laplacian positional encoding\n",
    "pos_enc_dim=10\n",
    "indices=torch.cat([train_idx,val_idx,test_idx])\n",
    "for idx in tqdm(indices, desc=\"Computing Laplacian PE\"):\n",
    "    g,_=dataset[idx]\n",
    "    g.ndata[\"PE\"]=dgl.lap_pe(g,k=pos_enc_dim,padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa5e41df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def train(model,loader,loss_fn,optimizer,device):\n",
    "    total_loss=0\n",
    "    model.train()\n",
    "    for i,(batch,labels) in enumerate(loader):\n",
    "        batch,labels=batch.to(device),labels.to(device)\n",
    "        \n",
    "        out_logits=model(batch,batch.ndata[\"feat\"],batch.ndata[\"PE\"])\n",
    "        \n",
    "        loss=loss_fn(out_logits,labels.float())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss+=loss.item()\n",
    "        \n",
    "        if i%20==0 or i==len(loader)-1:\n",
    "            print(f\"Iteration: {i} | Loss: {loss:.4f}\")\n",
    "    \n",
    "    return total_loss/len(loader)\n",
    "\n",
    "def evaluation(model,loader,evaluator,device):\n",
    "    # we use API evaluate for ogbg-molhiv which computes ROCAUC\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        y_true, y_pred=[],[]\n",
    "\n",
    "        for batch,labels in loader:\n",
    "\n",
    "            batch,labels=batch.to(device), labels.to(device)\n",
    "            y_hat=model(batch,batch.ndata[\"feat\"],batch.ndata[\"PE\"]) # logits\n",
    "\n",
    "            y_true.append(labels.view(y_hat.shape,).detach().cpu())\n",
    "            y_pred.append(y_hat.detach().cpu())\n",
    "\n",
    "        y_true=torch.cat(y_true,dim=0).numpy()\n",
    "        y_pred=torch.cat(y_pred,dim=0).numpy()\n",
    "\n",
    "        input_dict={\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "        score=evaluator.eval(input_dict)[\"rocauc\"]\n",
    "    \n",
    "    return score\n",
    "\n",
    "def train_and_test(model,train_loader,val_loader,test_loader,\n",
    "                   num_epochs,loss_fn,optimizer,evaluator,device):\n",
    "    best_val_rocauc=0.0\n",
    "    best_model=None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        print(\"----- Training ------\")\n",
    "        train_loss=train(model,train_loader,loss_fn,optimizer,device)\n",
    "        \n",
    "        print(\"----- Evaluating ----\")\n",
    "        train_rocauc=evaluation(model,train_loader,evaluator,device)\n",
    "        val_rocauc=evaluation(model,val_loader,evaluator,device)\n",
    "        test_rocauc=evaluation(model,test_loader,evaluator,device)\n",
    "                \n",
    "        # save the best model\n",
    "        if val_rocauc>best_val_rocauc:\n",
    "            best_val_rocauc=val_rocauc\n",
    "            best_model=copy.deepcopy(model)\n",
    "            \n",
    "        print(f'Train loss: {train_loss:.4f} | train_roc: {train_rocauc:.4f} | '\n",
    "         f'val_rocauc: {val_rocauc:.4f} | test_rocauc: {test_rocauc:.4f}')\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb3a2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained performance\n",
      "train_rocauc : 0.3960 | val_rocauc : 0.3960 | test_rocauc : 0.3593\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(\"ogbg-molhiv\")\n",
    "\n",
    "model=GTModel()\n",
    "device=torch.device(\"cpu\")\n",
    "loss_fn=torch.nn.BCEWithLogitsLoss() \n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "# print pre-trained performance of the model\n",
    "train_rocauc=evaluation(model,train_loader,evaluator,device)\n",
    "val_rocauc=evaluation(model,val_loader,evaluator,device)\n",
    "test_rocauc=evaluation(model,test_loader,evaluator,device)\n",
    "print(\"Pretrained performance\")\n",
    "print(f\"train_rocauc : {train_rocauc:.4f} | val_rocauc : {train_rocauc:.4f} | test_rocauc : {test_rocauc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5135d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "----- Training ------\n",
      "Iteration: 0 | Loss: 0.4708\n",
      "Iteration: 20 | Loss: 0.2386\n",
      "Iteration: 40 | Loss: 0.3987\n",
      "Iteration: 60 | Loss: 0.0679\n",
      "Iteration: 62 | Loss: 0.0725\n",
      "----- Evaluating ----\n",
      "Train loss: 0.2238 | train_roc: 0.6089 | val_rocauc: 0.5358 | test_rocauc: 0.4209\n",
      "Epoch: 1\n",
      "----- Training ------\n",
      "Iteration: 0 | Loss: 0.1227\n",
      "Iteration: 20 | Loss: 0.4018\n",
      "Iteration: 40 | Loss: 0.2443\n",
      "Iteration: 60 | Loss: 0.1868\n",
      "Iteration: 62 | Loss: 0.0694\n",
      "----- Evaluating ----\n",
      "Train loss: 0.1894 | train_roc: 0.6726 | val_rocauc: 0.6092 | test_rocauc: 0.5316\n",
      "Epoch: 2\n",
      "----- Training ------\n",
      "Iteration: 0 | Loss: 0.0429\n",
      "Iteration: 20 | Loss: 0.5700\n",
      "Iteration: 40 | Loss: 0.0285\n",
      "Iteration: 60 | Loss: 0.2035\n",
      "Iteration: 62 | Loss: 0.2587\n",
      "----- Evaluating ----\n",
      "Train loss: 0.1725 | train_roc: 0.6861 | val_rocauc: 0.5915 | test_rocauc: 0.5178\n",
      "Epoch: 3\n",
      "----- Training ------\n",
      "Iteration: 0 | Loss: 0.2680\n",
      "Iteration: 20 | Loss: 0.0467\n",
      "Iteration: 40 | Loss: 0.1686\n",
      "Iteration: 60 | Loss: 0.0521\n",
      "Iteration: 62 | Loss: 0.0416\n",
      "----- Evaluating ----\n",
      "Train loss: 0.1645 | train_roc: 0.7281 | val_rocauc: 0.5773 | test_rocauc: 0.5511\n",
      "Epoch: 4\n",
      "----- Training ------\n",
      "Iteration: 0 | Loss: 0.1477\n",
      "Iteration: 20 | Loss: 0.0545\n",
      "Iteration: 40 | Loss: 0.1502\n",
      "Iteration: 60 | Loss: 0.2195\n",
      "Iteration: 62 | Loss: 0.2087\n",
      "----- Evaluating ----\n",
      "Train loss: 0.1616 | train_roc: 0.7080 | val_rocauc: 0.6776 | test_rocauc: 0.4598\n"
     ]
    }
   ],
   "source": [
    "# train the model and print out performance\n",
    "num_epochs=5\n",
    "best_model=train_and_test(model,train_loader,val_loader,test_loader,\n",
    "                   num_epochs,loss_fn,optimizer,evaluator,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf3ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on test set\n",
    "# best_model_rocauc=evaluation(best_model,test_loader,evaluator,device)\n",
    "# print(f\"Best model rocauc on test set: {best_model_rocauc*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df50ec83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
